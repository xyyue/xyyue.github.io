<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0034)https://ai.stanford.edu/~xiangyufang/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style>
    .tooltip {
      position: relative;
    }

    .tooltip .tooltiptext {
      visibility: hidden;
      width: 130px;
      background-color: white;
      color: #000;
      text-align: center;
      border-radius: 6px;
      padding: 5px 0;

      /* Position the tooltip */
      position: absolute;
      z-index: 1;
      top: -3px;
      left: 76%;
    }

    .tooltip:hover .tooltiptext {
      visibility: visible;
      text-align: center;
      font-size: 33px;
    }

    .tooltip .tooltiptext a {
      color: #000;
    }
  </style>

	
		
	
		<title>Xiangyu Yue</title>
			
    <link rel="icon" type="image/png" href="./Xiangyu_files/seal_icon.png">

		<!-- CSS -->
    <link href="./Xiangyu_files/css" rel="stylesheet">
    <link rel="stylesheet" href="./Xiangyu_files/style.css" type="text/css" media="screen">
    <link rel="stylesheet" href="./Xiangyu_files/jquery.popup.css" type="text/css">
		<!-- ENDS CSS -->


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FL8BLLY4LY"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-FL8BLLY4LY');
    </script>

	</head>	

	<body data-new-gr-c-s-check-loaded="14.1014.0" data-gr-ext-installed="">
    <div class="section">
      <table id="personal">
        <tbody><tr>
          <td id="basic">
            <div>
              <br>
              <div class="tooltip" align="center">
                <h1>Xiangyu Yue</h1>
                <!-- <span class="tooltiptext"><a href="https://en.wiktionary.org/wiki/%E5%B2%B3" target="_blank">岳</a> <a href="https://en.wiktionary.org/wiki/%E7%BF%94" target="_blank">翔</a> <a href="https://en.wiktionary.org/wiki/%E5%AE%87" target="_blank">宇</a></span> -->
              </div>
              <br>
              <h2><b>Email</b>: xyyue [at] ie [dot] cuhk [dot] edu [dot] hk</h2>
              <!-- <br> -->
            </div>
          </td>
        </tr>

        <tr>

          <td id="bio">
            <div>
                I am currently an Assistant Professor in the <a href="https://www.ie.cuhk.edu.hk/main/index.shtml">Department of Information Engineering</a> at <a href="https://www.cuhk.edu.hk/english/index.html">the Chinese University of Hong Kong</a>. Before joining <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Lab</a>, 
                  I received my PhD from <a href="https://eecs.berkeley.edu/">Electrical Engineering and Computer Science</a> at University of California, Berkeley, working with <a href="https://people.eecs.berkeley.edu/~alberto/">Prof. Alberto Sangiovanni Vincentelli</a> and <a href="https://people.eecs.berkeley.edu/~keutzer">Prof. Kurt Keutzer</a> at <a href="https://bair.berkeley.edu/">Berkeley AI Research</a>. I am broadly interested in various areas including but not limited to: computer vision, multi-modal learning, generative models, foundation model, transfer learning, domain adaptation, interpretable systems, etc. 
                <br><br>
                Prior to Berkeley, I received my M.S. degree from <a href="https://www.stanford.edu/">Stanford University</a> and B.S. degree from <a href="https://www.nju.edu.cn/EN/">Nanjing University</a>. I did internships at <a href="https://research.google/">Google Research</a>, <a href="https://blog.x.company/inside-robotics-at-x-caa134ac854b">Google [x] Robotics</a>, <a href="http://research.baidu.com/Research_Areas/index-view?id=58">Baidu AI Research</a>, and <a href="https://ai.tencent.com/ailab/en/index">Tencent AI Lab</a>. I have received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/146/">Lotfi A. Zadeh Prize</a> for my research work.
                <br><br>
                <span id="myb">*NEW*</span>
                <span id="mybk"> I have multiple fully-funded PhD, MPhil, postdoc, RA, and intern positions available. Feel free to Email me if you are interested.</span>
                <br><br>
                <h2>
                  <a href="https://scholar.google.com/citations?user=-xQ-C1sAAAAJ&hl=en&authuser=1">Google Scholar</a>
                  <!-- &nbsp;&nbsp;|&nbsp;&nbsp; -->
                  <!-- <a href="https://github.com/xyyue">GitHub</a> -->
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.linkedin.com/in/xiangyu-yue-b96231a3/">LinkedIn</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://twitter.com/YueXiangyu">Twitter</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp; 
                  <a href="https://dblp.org/pid/207/7518.html">DBLP</a>
                </h2>
            </div>
          </td>

          <td id="photo">
           <div id="profile-img">
              <img src="./Xiangyu_files/yue_new.jpeg">
            </div>
            <!-- <div class="profile-img1"></div> -->
            <!--<div class="img">-->

              <!--<img src="./Xiangyu_files/yue_new.jpeg" class="hover_img">-->
              <!--<img src="./Xiangyu_files/yuexiangyu.jpeg" class="hover_img"> -->
              
              <!--</div>-->
              
          </td>

        </tr>
      </tbody></table>
    </div>

    <div id="info">

      <!-- <div class="section"> -->
        <!-- <h1>News</h1><br> -->

        <!-- <ul> -->
          <!-- <li>We have two papers accepted at <a href="https://eccv2022.ecva.net/">ECCV 2022</a>. </li> -->
          <!-- <li>I am a Graduate Student Instructor of <a href="https://pages.github.berkeley.edu/UCB-EECS208/course_site/"> EECS 208 </a> working with Prof. <a href="https://people.eecs.berkeley.edu/~yima/">Yi Ma</a> and Prof. <a href="https://people.eecs.berkeley.edu/~jiantao/">Jiantao Jiao</a>. </li> -->
          <!-- <li>I am honored to receive the Berkeley EECS Student Award: <a href="https://www2.eecs.berkeley.edu/Students/Awards/146/">Lotfi A. Zadeh Prize</a>.</li> -->
          <!-- <li> We have one paper accepted at <a href="http://iccv2021.thecvf.com/home"> ICCV 2021</a> and one at <a href="http://cvpr2021.thecvf.com/"> CVPR 2021</a>.</li> -->
          <!-- <li> We have one paper accepted at <a href="http://cvpr2021.thecvf.com/"> CVPR 2021</a>.</li> -->
          <!-- <li> We have one paper accepted at <a href="https://cis.ieee.org/publications/t-neural-networks-and-learning-systems"> TNNLS</a>, and one at <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221036">TCYB</a>.</li> -->
        <!-- </ul> -->
      <!-- </div> -->

      <!-- <div class="section"> -->
      <!--   <h1>Preprints</h1><br> -->
      <!--   <table id="publications"> -->
      <!--   </table> -->
      <!-- </div> -->

      <div class="section">
        <h1>Selected Papers
          [<a href="https://scholar.google.com/citations?hl=en&user=-xQ-C1sAAAAJ&view_op=list_works&authuser=1&sortby=pubdate"> Full List </a>]
        </h1>
        
        <br>
        <table id="publications">

          <tbody>

            <tr>
              <td id="publications-image">
                <img src="./Xiangyu_files/meta-transformer.png">
              </td>
              <td id="publications-info">
                <p>
                  <span id="paper">
                    Meta-Transformer: A Unified Framework for Multimodal Learning
                  </span>
                  <br>
                  <span id="author">
                    Yiyuan Zhang, Kaixiong Gong, Kaipeng Zhang, Hongsheng Li, Yu Qiao, Wanli Ouyang, Xiangyu Yue
                  </span>
                  <br>
                  Preprint 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2307.10802.pdf">PDF</a> |
                  <a href="https://kxgong.github.io/meta_transformer">Project</a> |
                  <a href="https://github.com/invictus717/MetaTransformer">Code</a> |
                  <a href="https://xyue.io">BibTex</a>
                </p>
              </td>
            </tr>

            <tr>
              <td id="publications-image">
                <img src="./Xiangyu_files/llama-adapter.png">
              </td>
              <td id="publications-info">
                <p>
                  <span id="paper">
                    LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model
                  </span>
                  <br>
                  <span id="author">
                    Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xiangyu Yue, Hongsheng Li, Yu Qiao
                  </span>
                  <br>
                  Preprint 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2304.15010.pdf">PDF</a> |
                  <a href="https://github.com/OpenGVLab/LLaMA-Adapter">Code</a> |
                  <a href="https://xyue.io">BibTex</a>
                </p>
              </td>
            </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/s4.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation
                </span>
                <br>
                <span id="author">
                  Changqi Wang, Haoyu Xie, Yuhui Yuan, Chong Fu, Xiangyu Yue
                </span>
                <br>
                International Conference on Computer Vision (ICCV) 2023
                <br>
                <a href="https://arxiv.org/pdf/2307.15539.pdf">PDF</a> |
                <a href="https://github.com/damianliumin/non-adversarial_backdoor">Code</a> |
                <a href="https://xyue.io">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/backdoor.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Beating Backdoor Attack at Its Own Game
                </span>
                <br>
                <span id="author">
                  Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue
                </span>
                <br>
                International Conference on Computer Vision (ICCV) 2023
                <br>
                <a href="https://arxiv.org/pdf/2307.15539.pdf">PDF</a> |
                <a href="https://github.com/damianliumin/non-adversarial_backdoor">Code</a> |
                <a href="https://xyue.io/bibtex/backdoor.bib">BibTex</a>
              </p>
            </td>
          </tr>


        <tr>
          <td id="publications-image">
            <img src="./Xiangyu_files/preventing.png">
          </td>
          <td id="publications-info">
            <p>
              <span id="paper">
                Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models
              </span>
              <br>
              <span id="author">
                Zangwei Zheng, Mingyuan Ma, Kai Wang, Ziheng Qin, Xiangyu Yue, Yang You
              </span>
              <br>
              International Conference on Computer Vision (ICCV) 2023
              <br>
              <a href="https://arxiv.org/pdf/2303.06628.pdf">PDF</a> |
              <a href="https://github.com/Thunderbeee/ZSCL">Code</a> |
              <a href="https://xyue.io">BibTex</a>
            </p>
          </td>
        </tr>
        

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/image2point.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models
                </span>
                <br>
                <span id="author">
                  Chenfeng Xu, Shijia Yang, Tomer Galanti, Bichen Wu, Xiangyu Yue, Bohan Zhai, Wei Zhan, Kurt Keutzer, Peter Vajda, Masayoshi Tomizuka
                </span>
                <br>
                European Conference on Computer Vision (ECCV) 2022
                <br>
                <a href="https://arxiv.org/pdf/2106.04180.pdf">PDF</a> |
                <a href="https://github.com/chenfengxu714/image2point">Code</a> |
                <a href="https://xyue.io/bibtex/image2point.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/MLSeg.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  MLSeg: Image and Video Segmentation as Multi-Label Classification and Selected-Label Pixel Classification
                </span>
                <br>
                <span id="author">
                  Haodi He, Yuhui Yuan, Xiangyu Yue, Han Hu
                </span>
                <br>
                European Conference on Computer Vision (ECCV) 2022
                <br>
                <a href="https://arxiv.org/pdf/2203.04187.pdf">PDF</a> |
                <a href="https://github.com/openseg-group/MLSeg">Code</a> |
                <a href="https://xyue.io/bibtex/MLSeg.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/pandemic.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Conditional Synthetic Data Generation for Robust Machine Learning Applications with Limited Pandemic Data
                </span>
                <br>
                <span id="author">
                  Hari P. Das, Ryan Tran, Japjot Singh, Xiangyu Yue, Geoff Tison, Alberto Sangiovanni Vincentelli, Costas Spanos
                </span>
                <br>
                AAAI Conference on Artificial Intelligence (AAAI), 2022
                <br>
                <a href="https://arxiv.org/pdf/2109.06486.pdf">PDF</a> |
                <a href="./Xiangyu_files/bibs/pandemic.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/hpt.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Self-Supervised Pretraining Improves Self-Supervised Pretraining
                </span>
                <br>
                <span id="author">
                  Colorado Reed*, Xiangyu Yue*, Ani Nrusimha, Sayna Ebrahimi, Vivek Vijaykumar, Richard Mao, Bo Li, Shanghang Zhang, Devin Guillory, Sean Metzger, Kurt Keutzer, Trevor Darrell
                  (* indicates equal contribution)
                </span>
                <br>
                Winter Conference on Applications of Computer Vision (WACV) 2022
                <br>
                <a href="https://arxiv.org/pdf/2103.12718.pdf">PDF</a> |
                <a href="https://github.com/cjrd/self-supervised-pretraining">Code</a> |
                <a href="https://xyue.io/bibtex/hpt.bib">BibTex</a>
              </p>
            </td>
          </tr>

            
          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/mfda.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Multi-source Few-shot Domain Adaptation
                </span>
                <br>
                <span id="author">
                  Xiangyu Yue, Zangwei Zheng, Colorado Reed, Hari Prasanna Das, Kurt Keutzer, Alberto Sangiovanni Vincentelli
                </span>
                <br>
                Preprint 2021
                <br>
                <a href="https://arxiv.org/pdf/2109.12391.pdf">PDF</a> |
                <a href="http://people.eecs.berkeley.edu/~xyyue">Code to come</a> |
                <a href="./Xiangyu_files/bibs/mfda.bib">BibTex</a>
              </p>
            </td>
          </tr>
        
          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/occo.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Unsupervised Point Cloud Pre-Training via View-Point Occlusion, Completion
                </span>
                <br>
                <span id="author">
                  Hanchen Wang, Qi Liu, Xiangyu Yue, Joan Lasenby, Matthew J. Kusner
                </span>
                <br>
                International Conference on Computer Vision (ICCV), 2021
                <br>
                <a href="https://arxiv.org/pdf/2010.01089.pdf">PDF</a> |
                <a href="https://github.com/hansen7/OcCo">Code</a> |
                <a href="https://xyue.io/bibtex/occo.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/longtail.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  On Ensemble Methods for Long-Tailed Recognition
                </span>
                <br>
                <span id="author">
                  Xiangyu Yue, Yang Zhang, Zhewei Yao, Sicheng Zhao, Kurt Keuzer, Alberto Sangiovanni Vincentelli, Boqing Gong
                </span>
                <br>
                Preprint 2021
                <br>
                <a href="https://xyue.io/files/long-tail-ensemble.pdf">PDF</a> |
                <a href="http://people.eecs.berkeley.edu/~xyyue">Code to come</a> |
                <a href="http://people.eecs.berkeley.edu/~xyyue">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/augprune.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  AugPrune: Robust Network Pruning via Augmented Data
                </span>
                <br>
                <span id="author">
                  Alex Zhao, Yaoqing Yang, Xiangyu Yue, Zhuang Liu, Elicia Ye, Michael Mahoney, Ramchandran Kannan, Joseph Gonzalez, Kurt Keutzer
                </span>
                <br>
                Preprint 2021
                <br>
                <a href="http://people.eecs.berkeley.edu/~xyyue">PDF</a> |
                <a href="http://people.eecs.berkeley.edu/~xyyue">Code to come</a> |
                <a href="http://people.eecs.berkeley.edu/~xyyue">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/radar.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Scene-aware Learning Network for Radar Object Detection
                </span>
                <br>
                <span id="author">
                  Zangwei Zheng, Xiangyu Yue, Kurt Keutzer, Alberto Sangiovanni Vincentelli
                </span>
                <br>
                International Conference on Multimedia Retrieval (ICMR) 2021
                <br>
                <a href="https://arxiv.org/pdf/2107.01469.pdf">PDF</a> |
                <a href="./Xiangyu_files/bibs/radar.bib">BibTex</a>
              </p>
            </td>
          </tr>
          
            <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/prototypical.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Prototypical Cross-domain Self-supervised Learning for Few-shot Unsupervised Domain Adaptation
                </span>
                <br>
                <span id="author">
                  <!-- <span id="author-xiangyu">Xiangyu Yue*</span>, -->
                  Xiangyu Yue*,
                  Zangwei Zheng*,
                  Shanghang Zhang,
                  Yang Gao,
                  Trevor Darrell,
                  Kurt Keutzer,
                  Alberto Sangiovanni-Vincentelli (* indicates equal contribution)
                </span>
                <br>
                IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2021
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yue_Prototypical_Cross-Domain_Self-Supervised_Learning_for_Few-Shot_Unsupervised_Domain_Adaptation_CVPR_2021_paper.pdf">PDF</a> |
                <a href="http://xyue.io/pcs-fuda/">Website</a> |
                <a href="https://github.com/zhengzangw/PCS-FUDA">Code</a> | 
                <a href="https://www.youtube.com/watch?v=SV0YOPNPEis">Video</a> |  
                <a href="https://xyue.io/files/2021-cvpr-prototypical.pdf">Poster</a> | 
                <a href="https://xyue.io/bibtex/proto-cvpr2021.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/www.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Curriculum Cyclegan for Textual Sentiment Domain Adaptation with Multiple Sources
                </span>
                <br>
                <span id="author">
                  Sicheng Zhao*, 
                  Yang Xiao*, 
                  Jiang Guo*, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue*</span>, -->
                  Xiangyu Yue*,
                  Jufeng Yang, Ravi Krishna, Pengfei Xu, Kurt Keutzer
                  (* indicates equal contribution)
                </span>
                <br>
                The Web Conference (WWW) 2021
                <br>
                <a href="https://arxiv.org/pdf/2011.08678.pdf">PDF</a> |
                <a href="https://github.com/WArushrush/Curriculum-CycleGAN">Code</a> |
                <a href="https://xyue.io/bibtex/www.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/emotion.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Emotional Semantics-preserved and Feature-aligned CycleGAN for Visual Emotion Adaptation
                </span>
                <br>
                <span id="author">
                  Sicheng Zhao, 
                  Xuanbai Chen,  
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Chuang Lin, Pengfei Xu, Ravi Krishna, Jufeng Yang, Guiguang Ding, Alberto Sangiovanni-Vincentelli, Kurt Keutzer
                </span>
                <br>
                IEEE Transactions on Cybernetics (TCYB) 2021
                <br>
                <a href="https://arxiv.org/pdf/2011.12470.pdf">PDF</a> |
                <!-- <a href="https://github.com/WArushrush/Curriculum-CycleGAN">Code</a> | -->
                <a href="https://xyue.io/bibtex/tcyb.bib">BibTex</a>
              </p>
            </td>
          </tr>
          
          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/tnnls.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  A Review of Single-Source Deep Unsupervised Visual Domain Adaptation
                </span>
                <br>
                <span id="author">
                  Sicheng Zhao, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue#,
                  Shanghang Zhang, Bo Li, Han Zhao, Bichen Wu, Ravi Krishna, Joseph E Gonzalez, Alberto L Sangiovanni-Vincentelli, Sanjit A Seshia, Kurt Keutzer (# indicates corresponding author)

                </span>
                <br>
                IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020
                <br>
                <a href="https://arxiv.org/pdf/2009.00155.pdf">PDF</a> |
                <a href="https://xyue.io/bibtex/tnnls.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/polarnet.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation
                </span>
                <br>
                <span id="author">
                  Yang Zhang, Zixiang Zhou, Philip David, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Zerong Xi, Boqing Gong, Hassan Foroosh
                </span>
                <br>
                IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2020
                <br>
                <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_PolarNet_An_Improved_Grid_Representation_for_Online_LiDAR_Point_Clouds_CVPR_2020_paper.pdf">PDF</a> |
                <a href="https://github.com/edwardzhou130/PolarSeg">Code</a> |
                <a href="https://xyue.io/bibtex/polarnet.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/scenic.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Scenic: a Language for Scenario Specification and Scene Generation
                </span>
                <br>
                <span id="author">
                  Daniel J Fremont, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue*</span>, -->
                  Xiangyu Yue*, 
                  Tommaso Dreossi*, Shromona Ghosh*, Alberto L Sangiovanni-Vincentelli, Sanjit A Seshia (* indicates equal contribution)
                </span>
                <br>
                ACM Conference on Programming Language Design and Implementation (PLDI) (2019)
                <br>
                <a href="https://arxiv.org/pdf/1809.09310v1.pdf">PDF</a> |
                <a href="https://github.com/aertslab/SCENIC">Code (Scenic)</a> |
                <a href="https://github.com/xyyue/scenic2gta">Code (Scenic2GTA)</a> | 
                <a href="https://xyue.io/bibtex/pldi.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/drpc.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization without Accessing Target Domain Data
                </span>
                <br>
                <span id="author">
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Yang Zhang, Sicheng Zhao, Alberto Sangiovanni-Vincentelli, Kurt Keutzer, Boqing Gong
                </span>
                <br>
                International Conference on Computer Vision (ICCV), 2019
                <br>
                <a href="https://arxiv.org/pdf/1909.00889.pdf">PDF</a> |
                <!-- <a href="https://github.com/WArushrush/Curriculum-CycleGAN">Code</a> | -->
                <a href="https://xyue.io/bibtex/drpc.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/madan.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Multi-source Domain Adaptation for Semantic Segmentation
                </span>
                <br>
                <span id="author">
                  Sicheng Zhao*, Bo Li*, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue*</span>, -->
                  Xiangyu Yue*,
                  Yang Gu, Pengfei Xu, Runbo Hu, Hua Chai, Kurt Keutzer (* indicates equal contribution)
                </span>
                <br>
                Advances in Neural Information Processing Systems (NeurIPS) 2019
                <br>
                <a href="https://arxiv.org/pdf/1910.12181.pdf">PDF</a> |
                <a href="https://github.com/Luodian/MADAN">Code</a> |
                <a href="https://xyue.io/bibtex/madan.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/squeezesegv2.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud
                </span>
                <br>
                <span id="author">
                  Bichen Wu*, Xuanyu Zhou*, Sicheng Zhao*, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Kurt Keutzer (* indicates equal contribution)
                </span>
                <br>
                International Conference on Robotics and Automation (ICRA) 2019
                <br>
                <a href="https://arxiv.org/pdf/1809.08495.pdf">PDF</a> |
                <a href="https://github.com/xuanyuzhou98/SqueezeSegV2">Code</a> |
                <a href="https://xyue.io/bibtex/squeezesegv2.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/ijcai.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Counterexample-guided Data Augmentation
                </span>
                <br>
                <span id="author">
                  Tommaso Dreossi, Shromona Ghosh, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Kurt Keutzer, Alberto Sangiovanni-Vincentelli, Sanjit A Seshia
                </span>
                <br>
                International Joint Conference on Artificial Intelligence (IJCAI) 2018
                <br>
                <a href="https://arxiv.org/pdf/1805.06962.pdf">PDF</a> |
                <a href="https://github.com/dreossi/analyzeNN">Code</a> |
                <a href="https://xyue.io/bibtex/www.bib">BibTex</a>
              </p>
            </td>
          </tr>
          
          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/shift.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Shift: A Zero-flop, Zero-parameter Alternative to Apatial Convolutions
                </span>
                <br>
                <span id="author">
                  Bichen Wu, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue*</span>, -->
                  Xiangyu Yue*,
                  Alvin Wan*, Peter Jin, Sicheng Zhao, Noah Golmant, Amir Gholaminejad, Joseph Gonzalez, Kurt Keutzer (* indicates equal contribution)
                </span>
                <br>
                IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2018
                <br>
                <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Shift_A_Zero_CVPR_2018_paper.pdf">PDF</a> |
                <a href="https://github.com/alvinwan/shiftresnet-cifar">Code</a> |
                <a href="https://xyue.io/bibtex/shift.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/icmr.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  A LiDAR Point Cloud Generator: from a Virtual World to Autonomous Driving
                </span>
                <br>
                <span id="author">
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Bichen Wu, Sanjit A Seshia, Kurt Keutzer, Alberto L Sangiovanni-Vincentelli
                </span>
                <br>
                International Conference on Multimedia Retrieval (ICMR) 2018
                <br>
                <a href="https://arxiv.org/pdf/1804.00103.pdf">PDF</a> |
                <!-- <a href="https://github.com/WArushrush/Curriculum-CycleGAN">Code</a> | -->
                <a href="https://xyue.io/bibtex/icmr.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/atva.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Formal Specification for Deep Neural Networks
                </span>
                <br>
                <span id="author">
                  Sanjit A Seshia, Ankush Desai, Tommaso Dreossi, Daniel J Fremont, Shromona Ghosh, Edward Kim, Sumukh Shivakumar, Marcell Vazquez-Chanlatte, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span> -->
                  Xiangyu Yue
                </span>
                <br>
                International Symposium on Automated Technology for Verification and Analysis (ATVA) 2018
                <br>
                <a href="https://people.eecs.berkeley.edu/~sseshia/pubdir/atva18.pdf">PDF</a> |
                <!-- <a href="https://github.com/WArushrush/Curriculum-CycleGAN">Code</a> | -->
                <a href="https://xyue.io/bibtex/atva.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/squeezeseg.gif">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-time Road-object Segmentation from 3d LiDAR Point Cloud
                </span>
                <br>
                <span id="author">
                  Bichen Wu, Alvin Wan, 
                  <!-- <span id="author-xiangyu">Xiangyu Yue</span>, -->
                  Xiangyu Yue,
                  Kurt Keutzer
                </span>
                <br>
                International Conference on Robotics and Automation (ICRA) 2018
                <br>
                <a href="https://arxiv.org/pdf/1710.07368.pdf">PDF</a> |
                <a href="https://www.youtube.com/watch?v=Xyn5Zd3lm6s">Video</a> |
                <a href="https://github.com/BichenWuUCB/SqueezeSeg">Code</a> |
                <a href="https://xyue.io/bibtex/squeezeseg.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <!-- <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/squeezeseg.gif">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Integration of Hardware and Software Designs for Object Grasping and Transportation by a Mobile Robot with Navigation Guidance via a Unique Bearing-alignment Mechanism 
                </span>
                <br>
                <span id="author">
                  Junmin Wu,
                  <span id="author-xiangyu">Xiangyu Yue</span>,
                  Wei Li
                </span>
                <br>
                International Conference on Robotics and Automation (ICRA) 2018
                <br>
                <a href="https://arxiv.org/pdf/1710.07368.pdf">PDF</a> |
                <a href="https://www.youtube.com/watch?v=Xyn5Zd3lm6s">Video</a> |
                <a href="https://github.com/BichenWuUCB/SqueezeSeg">Code</a> |
                <a href="https://xyue.io/bibtex/squeezeseg.bib">BibTex</a>
              </p>
            </td>
          </tr> -->
          <!-- <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/apt-gen.gif">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Adaptive Procedural Task Generation for Hard-Exploration Problems
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang</span>,
                  Yuke Zhu,
                  Silvio Savarese,
                  Li Fei-Fei
                </span>
                <br>
                ICLR 2021
                <br>
                <a href="https://arxiv.org/pdf/2007.00350.pdf">PDF</a> |
                <a href="https://apt-gen.github.io/">Website</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2020aptgen.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/keto.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  KETO: Learning Keypoint Representations for Tool Manipulation
                </span>
                <br>
                <span id="author">
                  Zengyi Qin,
                  <span id="author-xiangyu">Kuan Fang</span>,
                  Yuke Zhu,
                  Li Fei-Fei,
                  Silvio Savarese
                </span>
                <br>
                ICRA 2020
                <br>
                <a href="https://arxiv.org/pdf/1910.11977.pdf">PDF</a> |
                <a href="https://sites.google.com/view/ke-to">Website</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/qin2019keto.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/cavin.gif">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Dynamics Learning with Cascaded Variational Inference for Multi-Step Manipulation
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang</span>,
                  Yuke Zhu,
                  Animesh Garg,
                  Silvio Savarese,
                  Li Fei-Fei
                </span>
                <br>
                CoRL 2019 (Oral Presentation)
                <br>
                <a href="https://arxiv.org/pdf/1910.13395.pdf">PDF</a> |
                <a href="http://pair.stanford.edu/cavin/">Website</a> |
                <a href="http://ai.stanford.edu/blog/cavin/">Blog</a> |
                <a href="https://github.com/StanfordVL/robovat/">Environment</a> |
                <a href="https://github.com/StanfordVL/cavin/">Code</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2019cavin.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/smt.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang,</span>
                  Alexander Toshev,
                  Li Fei-Fei, 
                  Silvio Savarese
                </span>
                <br>
                CVPR 2019
                <br>
                <a href="https://arxiv.org/pdf/1903.03878.pdf">PDF</a> |
                <a href="https://sites.google.com/view/scene-memory-transformer">Website</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2019smt.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/tognet.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang,</span>
                  Yuke Zhu,
                  Animesh Garg,
                  Andrey Kurenkov,
                  Viraj Mehta,
                  Li Fei-Fei,
                  Silvio Savarese
                </span>
                <br>
                RSS 2018 (Journal version in IJRR 2019)
                <br>
                <a href="https://arxiv.org/pdf/1806.09266.pdf">PDF (RSS 2018)</a> |
                <a href="https://doi.org/10.1177/0278364919872545">PDF (IJRR 2019)</a> |
                <a href="https://sites.google.com/view/task-oriented-grasp/">Website</a> |
                <a href="https://www.youtube.com/watch?v=vYExCFeKXhw&amp;feature=youtu.be">Video</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2018tog.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/mtda.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang</span>,
                  Yunfei Bai, 
                  Stefan Hinterstoisser, 
                  Silvio Savarese, 
                  Mrinal Kalakrishnan
                </span>
                <br>
                ICRA 2018
                <br>
                <a href="https://arxiv.org/pdf/1710.06422.pdf">PDF</a> |
                <a href="https://sites.google.com/view/multi-task-domain-adaptation/">Website</a> |
                <a href="https://www.youtube.com/watch?v=BR5bgPxjvRM">Video</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2018mtda.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/demo2vec.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Demo2Vec: Reasoning Object Affordances from Online Videos
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang</span>*,
                  Te-Lin Wu*, 
                  Daniel Yang, 
                  Silvio Savarese, 
                  Joseph J. Lim 
                  (* indicates equal contribution)
                </span>
                <br>
                CVPR 2018
                <br>
                <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Fang_Demo2Vec_Reasoning_Object_CVPR_2018_paper.pdf">PDF</a> |
                <a href="https://sites.google.com/view/demo2vec/">Website</a> |
                <a href="https://github.com/xiangyufang/opra">Code</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2018demo2vec.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/ran.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  Recurrent Autoregressive Networks for Online Multi-Object Tracking
                </span>
                <br>
                <span id="author">
                  <span id="author-xiangyu">Kuan Fang</span>,
                  Yu Xiang, 
                  Xiaocheng Li, 
                  Silvio Savarese
                </span>
                <br>
                WACV 2018
                <br>
                <a href="https://arxiv.org/pdf/1711.02741.pdf">PDF</a> |
                <a href="https://www.youtube.com/watch?v=2Wbo9eky6jY">Video</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/fang2018ran.bib">BibTex</a>
              </p>
            </td>
          </tr>

          <tr>
            <td id="publications-image">
              <img src="./Xiangyu_files/delay.png">
            </td>
            <td id="publications-info">
              <p>
                <span id="paper">
                  DeLay: Robust Spatial Layout Estimation for Cluttered Indoor Scenes
                </span>
                <br>
                <span id="author">
                  Saumitro Dasgupta,
                  <span id="author-xiangyu">Kuan Fang</span>*,
                   Kevin Chen*, 
                   Silvio Savarese 
                   (* indicates equal contribution)
                </span>
                <br>
                CVPR 2016
                <br>
                <a href="http://svl.stanford.edu/assets/papers/delay-robust-spatial.pdf">PDF</a> |
                <a href="http://deeplayout.stanford.edu/">Website</a> |
                <a href="https://ai.stanford.edu/~xiangyufang/bibtex/dasgupta2016delay.bib">BibTex</a>
              </p>
            </td>
          </tr> -->

        </tbody></table>
      </div>

      <div class="section">
        <h1>Awards and Honors</h1><br>

        <ul>
          <li><a href="https://www2.eecs.berkeley.edu/Students/Awards/146">Lotfi A. Zadeh Prize</a>, UC Berkeley, 2021</li>
          <li>Graduate Excellence Award, UC Berkeley, 2016</li>
          <!-- <li>Best Paper Award at the 31st IEEE International Conference on Computer Design (ICCD), 2013</li> -->
          <li>Outstanding Graduate, Nanjing University, 2014</li>
          <li>Merit Student, Jiangsu Province, 2013</li>
          <li>1st Prize in Robot Stacking Challenge, Educational Robot Competition of China, 2012</li>
          <li>Outstanding Student Award, Nanjing University, 2012</li>
          <li>National Scholarship, highest scholarship in China, 2011</li>
        </ul>
      </div>

      <div class="section">
        <h1>Teaching</h1><br>

        <ul>
          <li>Graduate Student Instructor, <a href="https://pages.github.berkeley.edu/UCB-EECS208/course_site/">Computational Principles for High-Dimensional Data Analysis (EECS 208)</a>, UC Berkeley, 2021</li>
          <li>Graduate Student Instructor, <a href="https://cs61c.org/su21/">Great Ideas in Computer Architecture (CS 61C)</a>, UC Berkeley, 2017</li>
          <li>Teaching Assistant, <a href="https://explorecourses.stanford.edu/search?view=catalog&filter-coursestatus-Active=on&q=CS%20241:%20Embedded%20Systems%20Workshop&academicYear=20152016">Embedded Systems Workshop (CS 241)</a>, Stanford University, 2015</li>
        </ul>
      </div>

    </div>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
          <p align="left">
            <font size="2">
              <a href="https://people.eecs.berkeley.edu/~barron/">Website template</a>
              <a href="https://ai.stanford.edu/~kuanfang">courtesy</a>
            </font>
          </p>
        </td>
      </tr>
    </tbody></table>

    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MQ25LJL"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

	

</body></html>
